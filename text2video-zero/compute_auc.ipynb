{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from statistics import mean, stdev\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "from diffusers import DPMSolverMultistepScheduler\n",
    "from tree_ring.inverse_stable_diffusion import InversableStableDiffusionPipeline\n",
    "import open_clip\n",
    "from tree_ring.optim_utils import *\n",
    "from tree_ring.io_utils import *\n",
    "import re\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "def extract_id(string):\n",
    "    match = re.search(r'sent(\\d+)_frames', string)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='diffusion watermark')\n",
    "parser.add_argument('--model_id', default='/root/.cache/huggingface/diffusers/models--stabilityai--stable-diffusion-2-1-base/snapshots/5ede9e4bf3e3fd1cb0ef2f7a3fff13ee514fdf06/')\n",
    "parser.add_argument('--test_num_inference_steps', default=None, type=int)\n",
    "parser.add_argument('--num_inference_steps', default=50, type=int)\n",
    "\n",
    "# watermark\n",
    "parser.add_argument('--w_mask_shape', default='circle')\n",
    "\n",
    "parser.add_argument('--w_measurement', default='l1_complex')\n",
    "parser.add_argument('--w_radius', default=10)\n",
    "parser.add_argument('--w_channel', default=0, type=int)\n",
    "\n",
    "\n",
    "# for image distortion\n",
    "\n",
    "parser.add_argument('--orig_img_no_w_path',default='../datas/videos/text2video-zero/static_radius:10/8frames_uniform' ,type=str)\n",
    "parser.add_argument('--orig_img_w_path',default='../datas/videos/text2video-zero/static_radius:10/8frames_uniform_w', type=str)\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "if args.test_num_inference_steps is None:\n",
    "    args.test_num_inference_steps = args.num_inference_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = DPMSolverMultistepScheduler.from_pretrained(args.model_id, subfolder='scheduler')\n",
    "pipe = InversableStableDiffusionPipeline.from_pretrained(\n",
    "    args.model_id,\n",
    "    scheduler=scheduler,\n",
    "    torch_dtype=torch.float16,\n",
    "    revision='fp16',\n",
    "    )\n",
    "pipe = pipe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester_prompt = '' # assume at the detection time, the original prompt is unknown\n",
    "text_embeddings = pipe.get_text_embedding(tester_prompt)\n",
    "\n",
    "# ground-truth patch\n",
    "gt_patch = torch.load('./tree_ring/key.pt').to(dtype=torch.complex32)\n",
    "init_latents_w = pipe.get_random_latents()\n",
    "watermarking_mask = get_watermarking_mask(init_latents_w, args, device)\n",
    "no_w_metrics=[]\n",
    "w_metrics=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_video in range(10):\n",
    "    for idx_frame in range(8):\n",
    "        frame_path_no_w = f'{args.orig_img_no_w_path}/sent{idx_video}_frames/frame{idx_frame}.jpg'\n",
    "        frame_path_w = f'{args.orig_img_w_path}/sent{idx_video}_frames/frame{idx_frame}.jpg'\n",
    "\n",
    "        img_no_w = Image.open(frame_path_no_w)\n",
    "        img_w = Image.open(frame_path_w)\n",
    "        img_no_w = transform_img(img_no_w).unsqueeze(0).to(text_embeddings.dtype).to(device)\n",
    "        img_w = transform_img(img_w).unsqueeze(0).to(text_embeddings.dtype).to(device)\n",
    "\n",
    "        image_latents_no_w = pipe.get_image_latents(img_no_w, sample=False)\n",
    "        image_latents_w = pipe.get_image_latents(img_w, sample=False)\n",
    "\n",
    "        reversed_latents_no_w = pipe.forward_diffusion(\n",
    "        latents=image_latents_no_w,\n",
    "        text_embeddings=text_embeddings,\n",
    "        guidance_scale=1,\n",
    "        num_inference_steps=args.test_num_inference_steps,\n",
    "        )\n",
    "\n",
    "        reversed_latents_w = pipe.forward_diffusion(\n",
    "        latents=image_latents_w,\n",
    "        text_embeddings=text_embeddings,\n",
    "        guidance_scale=1,\n",
    "        num_inference_steps=args.test_num_inference_steps,\n",
    "        )\n",
    "\n",
    "        no_w_metric, w_metric = eval_watermark(reversed_latents_no_w, reversed_latents_w, watermarking_mask, gt_patch, args)\n",
    "        no_w_metrics.append(-no_w_metric)\n",
    "        w_metrics.append(-w_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = no_w_metrics +  w_metrics\n",
    "t_labels = [0] * len(no_w_metrics) + [1] * len(w_metrics)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(t_labels, preds, pos_label=1)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "acc = np.max(1 - (fpr + (1 - tpr))/2)\n",
    "low = tpr[np.where(fpr<.01)[0][-1]]\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割原始列表，每8个元素为一组\n",
    "split_lists_no = [no_w_metrics[i:i+8] for i in range(0, len(no_w_metrics), 8)]\n",
    "\n",
    "# 计算每组的平均值\n",
    "average_values_no = [sum(sub_list) / len(sub_list) for sub_list in split_lists_no]\n",
    "\n",
    "# 分割原始列表，每8个元素为一组\n",
    "split_lists_w = [w_metrics[i:i+8] for i in range(0, len(w_metrics), 8)]\n",
    "\n",
    "# 计算每组的平均值\n",
    "average_values_w = [sum(sub_list) / len(sub_list) for sub_list in split_lists_w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = average_values_no +  average_values_w\n",
    "t_labels = [0] * len(average_values_no) + [1] * len(average_values_w)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(t_labels, preds, pos_label=1)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "acc = np.max(1 - (fpr + (1 - tpr))/2)\n",
    "low = tpr[np.where(fpr<.01)[0][-1]]\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "integrate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
